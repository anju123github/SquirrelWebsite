<!DOCTYPE html>
<html>

<head>
    <title>Squirrel-Codes</title>
    <link rel="stylesheet" href="../../../index.css">
    <link rel="shortcut icon" href="../../../images/logo-dark.svg" type="image/x-icon">
</head>

<body>

    <header class="sticky">
        <a href="index.html" class="webname">
            <img src="../../../images/logo-dark.svg" alt="">
            Squirrel<span class="primary-color">Codes</span>
        </a>
        <nav>
            <a href="../../../index.html">Home</a>
            <a href="../dbms-tutorial/dbms1.html">DBMS</a>
            <a href="../../plsql-tutorial/plsql1.html" class="active">PL/SQL</a>
            <a href="../java.html">Java</a>
            <a href="../../../about.html">About</a>
        </nav>
    </header>

    <h2 class="center tutorial">Java Tutorial</h2>
    <hr>
    <div class="content-box">
        <div class="sidebar">
            <a class="primary-color">Programs</a>
            <a href="../../../Programs/Program1.html" class="sidelinks sideactive">Program 1</a>
            <a href="./Quesrions/Array2D.html" class="sidelinks">Program 2</a>
            <a href="./Quesrions/Applets.html" class="sidelinks">Program 3</a>
            <a href="./Quesrions/Data-Conversion.html" class="sidelinks">Program 4</a>
            <a href="./Quesrions/Delegation-event-model.html" class="sidelinks">Delegation Event Model</a>
            <a href="./Quesrions/Exception-Handling.html" class="sidelinks">Exception handling</a>
            <a href="./Quesrions/Function.html" class="sidelinks">Functions</a>
            <a href="./Quesrions/AWT.html" class="sidelinks">AWT</a>
            <a href="./Quesrions/Inheritance.html" class="sidelinks">Inheritance</a>
            <a href="./Quesrions/Input-Output.html" class="sidelinks">Input/Output</a>
            <a href="./Quesrions/Interfaces.html" class="sidelinks">Interface</a>
            <a href="./Quesrions/JDBC.html" class="sidelinks">JDBC</a>
            <a href="./Quesrions/Multithreading.html" class="sidelinks">Multithreading</a>
            <a href="./Quesrions/OOPs.html" class="sidelinks">OOPs</a>
            <a href="./Quesrions/Packages.html" class="sidelinks">Packages</a>
            <a href="./Quesrions/Array1D.html" class="sidelinks">1D Arrays</a>
            <a href="./Quesrions/String.html" class="sidelinks">Strings</a>
        </div>
        <div class="content">
            <!-- topic name -->
            <h3 class="main">Multithreading</h3>

            <!-- Programs list -->
            <p>6. Write a Java program to implement a concurrent web crawler that crawls multiple websites simultaneously using threads.</p>
            <h3>Code</h3>
            <pre class="code"><code class="language-java">
                
             import java.io.IOException;
             import java.net.URL;
             import java.util.HashSet;
             import java.util.Set;
             import java.util.concurrent.ExecutorService;
             import java.util.concurrent.Executors;
             import java.util.concurrent.TimeUnit;
             
             public class ConcurrentWebCrawler {
             
                 private static final int MAX_DEPTH = 2;
                 private static final int MAX_THREADS = 5;
                 private static Set visitedUrls = new HashSet<>();
             
                 public static void main(String[] args) {
                     String seedUrl = "file:///path/to/your/example.html"; // Replace with the correct path to your HTML file
                     crawl(seedUrl, 0);
                 }
             
                 private static void crawl(String url, int depth) {
                     if (depth > MAX_DEPTH || visitedUrls.contains(url)) {
                         return;
                     }
             
                     System.out.println("Crawling: " + url + " at depth " + depth);
             
                     visitedUrls.add(url);
             
                     try {
                         String pageContent = fetchPage(url);
                         processPage(pageContent);
             
                         Set links = extractLinks(pageContent);
             
                         ExecutorService executor = Executors.newFixedThreadPool(MAX_THREADS);
             
                         for (String link : links) {
                             executor.execute(() -> crawl(link, depth + 1));
                         }
             
                         executor.shutdown();
                         executor.awaitTermination(Long.MAX_VALUE, TimeUnit.NANOSECONDS);
             
                     } catch (IOException | InterruptedException e) {
                         e.printStackTrace();
                     }
                 }
             
                 private static String fetchPage(String url) throws IOException {
                     // Simulate fetching the web page content using java.net.URL
                     // In a real-world scenario, you would use a library like HttpClient
                     // to make HTTP requests.
                     return "Content of " + url;
                 }
             
                 private static Set extractLinks(String pageContent) {
                     // Simulate extracting links from the page content
                     Set links = new HashSet<>();
                     links.add("http://example.com/link1");
                     links.add("http://example.com/link2");
                     links.add("http://example.com/link3");
                     return links;
                 }
             
                 private static void processPage(String pageContent) {
                     // Simulate processing the web page content
                     System.out.println("Processing page: " + pageContent);
                 }
             }
</code></pre>
<h3>Output</h3>
<pre class="code" style="padding: 2%;">
    Crawling: file:///path/to/your/example.html at depth 0
    Processing page: Content of file:///path/to/your/example.html
    Crawling: http://example.com/link1 at depth 1
    Crawling: http://example.com/link2 at depth 1
    Crawling: http://example.com/link3 at depth 1
    Processing page: Content of http://example.com/link1
    Processing page: Content of http://example.com/link2
    Processing page: Content of http://example.com/link3
    Crawling: http://example.com/link1 at depth 2
    Crawling: http://example.com/link2 at depth 2
    Crawling: http://example.com/link3 at depth 2
    Processing page: Content of http://example.com/link1
    Processing page: Content of http://example.com/link2
    Processing page: Content of http://example.com/link3
</pre>
            <!-- previous next buttons -->
            <!-- <div class="toggle-page-btns">
                <a href="plsql2.html" class="button">Next &rarr;</a>
            </div> -->
        </div>
    </div>
    <footer>
        Copyright &copy; 2023 Squirrel<span class="primary-color">Codes</span>
    </footer>
</body>

</html>